{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1452fdb9",
   "metadata": {},
   "source": [
    "__LLM Agent using LangChain__ \n",
    "\n",
    "This notebook, illustrate the creation of a simple AI Agent using an OpenAI model. We will use LangChain to allow the agent access to external data and tools. \n",
    "\n",
    "__LangChain__ \n",
    "- LangChain is a framework designed to connect LLM's with external data sources as well as computational tools\n",
    "- The core idea is chains. By chaining a series of actions together, an AI Agent can accomplish more complex tasks\n",
    "\n",
    "First, we will load the LLM. Next we will define the tools that agent can use. Next we will create the AI Agent and give it a task. \n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "Este cuaderno ilustra la creación de un Agente de IA simple usando un modelo de OpenAI. Usaremos LangChain para permitir que el agente acceda a datos y herramientas externas.\n",
    "\n",
    "__LangChain__\n",
    "- LangChain es un framework diseñado para conectar LLMs con fuentes de datos externas y herramientas computacionales\n",
    "- La idea central son las 'chains' (cadenas). Al encadenar una serie de acciones, un Agente de IA puede realizar tareas más complejas\n",
    "\n",
    "Primero cargaremos el LLM. Luego definiremos las herramientas que el agente puede usar. Después crearemos el Agente de IA y le asignaremos una tarea.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5627f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047120c1",
   "metadata": {},
   "source": [
    "The following cell loads the LLM we will use. We will use the gpt-4o model with a temperature of zero. \n",
    "\n",
    "Please note, rerunning this notebook will note work unless you set up your own connection to OpenAI models.\n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "La siguiente celda carga el LLM que usaremos. Usaremos el modelo gpt-4o con temperatura cero.\n",
    "\n",
    "Tenga en cuenta que volver a ejecutar este cuaderno no funcionará a menos que configure su propia conexión a los modelos de OpenAI.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6f02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "print(f\"Using LLM: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69618407",
   "metadata": {},
   "source": [
    "The following cells defines tools that the agent will utilize. For this example, the agent will be given tools to search Wikipedia. The __WikipediaAPIWrapper__ is a LangChain community tool that sets up a connection to Wikipedia. The wrapper will return the most relevant result and use up to 1000 characters to limit token usage. The __WikipediaQueryRun__ converts the wrapper into a tool that the agent can call. In this example we only have one tool, but agents can have many tools stored in a list as shown below. \n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "Las siguientes celdas definen las herramientas que el agente utilizará. Para este ejemplo, al agente se le darán herramientas para buscar en Wikipedia. El __WikipediaAPIWrapper__ es una herramienta de la comunidad de LangChain que configura una conexión a Wikipedia. El wrapper devolverá el resultado más relevante y usará hasta 1000 caracteres para limitar el uso de tokens. El __WikipediaQueryRun__ convierte el wrapper en una herramienta que el agente puede invocar. En este ejemplo solo tenemos una herramienta, pero los agentes pueden tener muchas herramientas almacenadas en una lista como se muestra a continuación.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ffb768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent has 1 tool(s) available: ['wikipedia']\n"
     ]
    }
   ],
   "source": [
    "# First, set up the Wikipedia API wrapper\n",
    "wikipedia_api_wrapper = WikipediaAPIWrapper(top_results=1, doc_content_chars_max=1000)\n",
    "\n",
    "# Then, create the tool itself\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper)\n",
    "\n",
    "# We'll put all our tools in a list\n",
    "tools = [wikipedia_tool]\n",
    "\n",
    "print(f\"Agent has {len(tools)} tool(s) available: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9fe54e",
   "metadata": {},
   "source": [
    "Now that the agent has a tool, we will prompt the agent. In order to do so, the agent needs instructions. LangChain provides pre-built prompts that help guide an agent on what tools to use and how to respond. The cell below uses a standard one from LangChain Hub. \n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "Ahora que el agente tiene una herramienta, lo solicitaremos mediante un prompt. Para ello, el agente necesita instrucciones. LangChain proporciona prompts preconstruidos que ayudan a guiar al agente sobre qué herramientas usar y cómo responder. La celda siguiente usa uno estándar del LangChain Hub.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4bfb966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent prompt loaded. It guides the LLM on how to reason and use tools.\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt for our agent from LangChain Hub\n",
    "# This prompt tells the LLM how to reason and use tools\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "print(\"Agent prompt loaded. It guides the LLM on how to reason and use tools.\")\n",
    "# You can uncomment the line below to see the prompt template:\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0b190",
   "metadata": {},
   "source": [
    "Now we will create the agent by passing the llm, tools and the prompt to be used. \n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "Ahora crearemos el agente pasando el llm, las herramientas y el prompt a usar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5da7acdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created!\n"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "print(\"Agent created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97ff40",
   "metadata": {},
   "source": [
    "Now we will run the agent. The question we will ask it is: \n",
    "\n",
    "- __What is Lionel Messi's middle name? And what city was he born in?__\n",
    "\n",
    "\n",
    "The components below have certain responsibilities: \n",
    "\n",
    "- __Agent Executor__ : The engine that executes the  agent's decisions\n",
    "- __agent=agent, tools=tools__: The agent logic and tools it has access to\n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "Ahora ejecutaremos el agente. La pregunta que le haremos es:\n",
    "\n",
    "- __¿Cuál es el segundo nombre de Lionel Messi? ¿Y en qué ciudad nació?__\n",
    "\n",
    "Los componentes que siguen tienen ciertas responsabilidades:\n",
    "\n",
    "- __Agent Executor__: El motor que ejecuta las decisiones del agente\n",
    "- __agent=agent, tools=tools__: La lógica del agente y las herramientas a las que tiene acceso\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96fb223a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with a question:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLionel Messi is a well-known figure, and I can provide information about him. However, to ensure accuracy, I will verify his middle name and birthplace.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Lionel Messi\u001b[0m\u001b[36;1m\u001b[1;3mPage: Lionel Messi\n",
      "Summary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] ; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one of the greatest players in history, Messi has set numerous records for individual accolades won throughout his professional footballing career, including eight Ballon d'Ors, six European Golden Shoes, and eight times being named the world's best player by FIFA. In 2025, he was named the All Time Men's World Best Player by the IFFHS. He is the most decorated player in the history of professional football having won 45 team trophies. Messi's records include most goals in a calendar year (91), most goals for a single club (672 for Barcelona), most goals in La Liga (474), most goal contributions in the FIFA World Cup (21), and most goal contributions in the Copa América (32). A prolific goalsco\u001b[0m\u001b[32;1m\u001b[1;3mI found the information I needed. \n",
      "\n",
      "Final Answer: Lionel Messi's middle name is Andrés, and he was born in the city of Rosario, Argentina.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Agent's Final Answer ---\n",
      "Lionel Messi's middle name is Andrés, and he was born in the city of Rosario, Argentina.\n"
     ]
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "print(\"Running the agent with a question:\")\n",
    "response = agent_executor.invoke({\"input\": \"What is Lionel Messi's middle name? And what city was he born in?\"})\n",
    "\n",
    "print(\"\\n--- Agent's Final Answer ---\")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66fad08",
   "metadata": {},
   "source": [
    "As seen above, the agent call wikipedia and searches for Lionel Messi. Within the wikipedia page, it is able to find his middle name and the city in which he was born. Lastly, the agent outputs the response. \n",
    "\n",
    "This is a simple example, with one chain but serves as an introduction to LangChain and the concepts that make it a powerful tool. \n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "Como se ve arriba, el agente llama a Wikipedia y busca a Lionel Messi. Dentro de la página de Wikipedia, puede encontrar su segundo nombre y la ciudad en la que nació. Finalmente, el agente muestra la respuesta.\n",
    "\n",
    "Este es un ejemplo simple, con una sola cadena, pero sirve como introducción a LangChain y a los conceptos que lo convierten en una herramienta poderosa.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d9975",
   "metadata": {},
   "source": [
    "__Additional Considerations__ \n",
    "\n",
    "In real world applications LangChain serves as a powerful tool used for different purposes. \n",
    "\n",
    "1. RAG (Retrieval Augmented Generation)\n",
    "- LangChain helps load a company's private data into readable context for an LLM \n",
    "- LangChain helps split this data into chunks and stores them in a Vector Store, which are efficient queried by an LLM \n",
    "- The RAG system is then able to efficiently retrieve and answer questions based on context provided \n",
    "\n",
    "2. Querying Database\n",
    "- LangChain can connect and LLM to a private database \n",
    "- Given the database structure, the LLM can write code to pull data \n",
    "- Therefore, a person can query a database in english and the LLM can correctly return the information desired \n",
    "- The impact, is less time writing basic SQL queries and empowering people to make decisions \n",
    "\n",
    "3. Agentic Workflows \n",
    "- By utilizing the concept of chains, an agent can complete multi-step complex tasks\n",
    "- By provided tools to an LLM through LangChain, an LLM take actions based on its decisions \n",
    "- Simple workflows such as booking a hotel or creating a reservation to a restaurant are already available due to tools like LangChain. \n",
    "\n",
    "\n",
    "\n",
    "<div style=\"color:#0b3d91\">\n",
    "\n",
    "__Consideraciones Adicionales__\n",
    "\n",
    "En aplicaciones del mundo real, LangChain actúa como una herramienta potente usada para diferentes propósitos.\n",
    "\n",
    "1. RAG (Retrieval Augmented Generation)\n",
    "- LangChain ayuda a cargar los datos privados de una empresa en un contexto legible para un LLM\n",
    "- LangChain ayuda a dividir estos datos en fragmentos y los almacena en un Vector Store, que son consultados eficientemente por un LLM\n",
    "- El sistema RAG puede recuperar y responder preguntas basadas en el contexto provisto\n",
    "\n",
    "2. Consultas a Bases de Datos\n",
    "- LangChain puede conectar un LLM a una base de datos privada\n",
    "- Dada la estructura de la base de datos, el LLM puede escribir código para extraer datos\n",
    "- Por lo tanto, una persona puede consultar una base de datos en inglés y el LLM puede devolver correctamente la información deseada\n",
    "- El impacto es menos tiempo dedicado a escribir consultas SQL básicas y empoderar a las personas para tomar decisiones\n",
    "\n",
    "3. Flujos de Trabajo Agénticos\n",
    "- Al utilizar el concepto de chains, un agente puede completar tareas complejas de múltiples pasos\n",
    "- Al proporcionar herramientas a un LLM a través de LangChain, un LLM puede tomar acciones basadas en sus decisiones\n",
    "- Flujos simples como reservar un hotel o crear una reserva en un restaurante ya están disponibles gracias a herramientas como LangChain.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
